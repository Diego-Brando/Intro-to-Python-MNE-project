{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working version : https://www.kaggle.com/code/daniil19189/exploration-of-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "\n",
    "data_train_path = '/kaggle/input/hms-harmful-brain-activity-classification/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from a CSV file into a DataFrame\n",
    "data = pd.read_csv(data_train_path)\n",
    "\n",
    "# Create a copy of the original DataFrame to avoid reloading data multiple times\n",
    "df = data.copy()  # Backup to avoid reloading\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the description of the datasets, the highest possible data quality is the agreement of five experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'eeg_id' and count the unique 'expert_consensus' values\n",
    "# This metric is used to assess the quality of the EEG recordings\n",
    "\n",
    "counts = df.groupby('eeg_id')['expert_consensus'].nunique() # используем как метрику качества записи\n",
    "\n",
    "# Identify EEG records that have more than 5,4,3 unique expert consensus values\n",
    "\n",
    "eeg_id_with_multiple_consensus_5 = counts[counts > 5].index.tolist()\n",
    "eeg_id_with_multiple_consensus_4 = counts[counts > 4].index.tolist()\n",
    "eeg_id_with_multiple_consensus_3 = counts[counts > 3].index.tolist()\n",
    "\n",
    "# Print the lists of EEG IDs \n",
    "\n",
    "print(eeg_id_with_multiple_consensus_5)\n",
    "print(eeg_id_with_multiple_consensus_4)\n",
    "print(eeg_id_with_multiple_consensus_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific EEG data file for analysis. We can review any files with 4 or 3 consensus levels.\n",
    "# Update: Treating category 3 as potentially problematic\n",
    "\n",
    "data_eeg_path = '/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/1460778765.parquet'\n",
    "\n",
    "df_multiple = df[df['eeg_id']==1460778765]\n",
    "data = pd.read_parquet(data_eeg_path).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройки каналов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'EKG' column because it's not present in the montage,\n",
    "# If not dropped now, all would be dropped later\n",
    "data = data.drop(['EKG'], axis=1) \n",
    "ch_names = data.columns.tolist()\n",
    "\n",
    "# Create a list of channel types, assuming all channels are EEG\n",
    "ch_types = ['eeg']*len(ch_names) \n",
    "\n",
    "# Create Info object for MNE, setting the sample frequency to 200 Hz\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=200)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a NumPy array and transpose it to fit MNE's data structure requirements\n",
    "data_values = data.values.T\n",
    "# Create an MNE RawArray object with the data and info structure\n",
    "raw = mne.io.RawArray(data_values, info)\n",
    "# Apply a notch filter at 50 Hz and bandpass filter from 0.1 to 45 Hz to the data\n",
    "raw = raw.notch_filter(50).filter(0.1, 45)\n",
    "# Define scaling factors for plotting EEG data\n",
    "scalings = {'eeg': 300} \n",
    "# Calculate the maximum duration to plot based on EEG label offsets, adding 50 seconds margin\n",
    "duration = df_multiple['eeg_label_offset_seconds'].max()+50\n",
    "# Set the standard 10-20 montage for EEG\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "# Plot the sensor positions with channel names\n",
    "raw.set_montage(ten_twenty_montage)\n",
    "# Plot the raw EEG data without scrollbars and scale bars, using the defined duration and scalings\n",
    "raw.plot_sensors(show_names=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# график для простмотра и отчистки данных\n",
    "raw.plot(show_scrollbars=False, show_scalebars=False, duration= duration, scalings=scalings)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Events and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from event types to integers\n",
    "Target = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
    "event_ids = {'Seizure':0, 'LPD':1, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
    "# Prepare events data by mapping expert_consensus using event_ids and adjusting time offsets\n",
    "events = df_multiple[['eeg_label_offset_seconds', 'expert_consensus']]\n",
    "events.insert(1, 'New', 0)\n",
    "events.loc[:,'expert_consensus'] = events['expert_consensus'].map(event_ids)\n",
    "events.loc[:,'eeg_label_offset_seconds'] = (events['eeg_label_offset_seconds']+25)*200\n",
    "events = events.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup of old events for comparison\n",
    "events_old = events \n",
    "# Plot the events to visualize their distribution in the data\n",
    "mne.viz.plot_events(events[:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Epochs from the raw data using the event markers, with each epoch from -5 to +5 seconds around the event\n",
    "epochs = mne.Epochs(raw, events, event_id = event_ids, tmin=-5, tmax=5, preload=True, baseline=(None, 0))\n",
    "# Plot the first 10 epochs with defined settings, showing all picks without scrollbars or scale bars\n",
    "epochs.plot(n_epochs=10, events=True, picks = 'all', show_scrollbars=False, show_scalebars=False, scalings=scalings)\n",
    "plt.tight_layout() # Fix overlapping epochs if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'eeg_label_offset_seconds' and 'expert_consensus' columns from df_multiple\n",
    "events = df_multiple[['eeg_label_offset_seconds', 'expert_consensus']]\n",
    "# Initialize a DataFrame to store non-overlapping events    \n",
    "non_overlapping_events = pd.DataFrame(columns=events.columns)\n",
    "\n",
    "# Convert 'eeg_label_offset_seconds' column to a list for processing\n",
    "list_eeg_label_offset_seconds = list(df_multiple['eeg_label_offset_seconds'])\n",
    "new_list = [] # List to store the new, non-overlapping event offsets\n",
    "current_offset = 0# Start with the initial offset\n",
    "min_distance = 10 # Minimum distance between events\n",
    "\n",
    "# Process to filter out overlapping events based on min_distance\n",
    "while current_offset <= max(list_eeg_label_offset_seconds):\n",
    "    new_list.append(current_offset)\n",
    "    # Find the next event that is at least min_distance away\n",
    "    next_offset = next((x for x in list_eeg_label_offset_seconds if x >= current_offset + min_distance), None)\n",
    "    if next_offset is None:\n",
    "        break\n",
    "    current_offset = next_offset\n",
    "\n",
    "# Select events that are in the new_list of non-overlapping events\n",
    "events = df_multiple[['eeg_label_offset_seconds', 'expert_consensus']]\n",
    "non_overlapping_events = pd.DataFrame(columns=events.columns)\n",
    "\n",
    "mask = events['eeg_label_offset_seconds'].isin(new_list)\n",
    "non_overlapping_events = events[mask]\n",
    "# Insert a new column with default value 0\n",
    "non_overlapping_events.insert(1, 'New', 0)\n",
    "# Map 'expert_consensus' to the corresponding numeric event ID\n",
    "non_overlapping_events.loc[:,'expert_consensus'] = non_overlapping_events['expert_consensus'].map(event_ids)\n",
    "# Adjust the 'eeg_label_offset_seconds' and scale by the sampling frequency\n",
    "non_overlapping_events.loc[:,'eeg_label_offset_seconds'] = (non_overlapping_events['eeg_label_offset_seconds']+25)*200\n",
    "non_overlapping_events = non_overlapping_events.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original events for comparison\n",
    "mne.viz.plot_events(events_old[:])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot non-overlapping events to show the filtering effect\n",
    "mne.viz.plot_events(non_overlapping_events[:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Epochs from the raw data using non-overlapping events\n",
    "epochs = mne.Epochs(raw, non_overlapping_events, event_id = event_ids, tmin=-5, tmax=5, preload=True, baseline=(None, 0))\n",
    "# Plot the first 10 epochs, showing the effect of non-overlapping event selection\n",
    "epochs.plot(n_epochs=10, events=True, picks = 'all', show_scrollbars=False, show_scalebars=False, scalings=scalings)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power spectral density for 'Seizure' events between 0.01 and 20 Hz\n",
    "epochs['Seizure'].plot_psd(fmin=0.01, fmax=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power spectral density for 'LPD' events between 0.01 and 20 Hz\n",
    "epochs['LPD'].plot_psd(fmin=0.01, fmax=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power spectral density for 'LRDA' events between 0.01 and 20 Hz\n",
    "epochs['LRDA'].plot_psd(fmin=0.01, fmax=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power spectral density for 'GRDA' events between 0.01 and 20 Hz\n",
    "epochs['GRDA'].plot_psd(fmin=0.01, fmax=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power spectral density for 'Other' events between 0.01 and 20 Hz\n",
    "epochs['Other'].plot_psd(fmin=0.01, fmax=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform time-frequency analysis using the Morlet wavelet transform for 'Seizure' events\n",
    "\n",
    "from mne.time_frequency import tfr_morlet, tfr_multitaper, tfr_stockwell\n",
    "freq = np.arange(0.5, 20, 0.01) # Define the range of frequencies\n",
    "n_cycles = freq/2 # Define the number of cycles for the wavelet transform\n",
    "\n",
    "# Compute the power for 'Seizure' events\n",
    "power_seizure = tfr_morlet(epochs['Seizure'][0], freq, n_cycles = n_cycles, return_itc = False)\n",
    "# Plot the time-frequency representation for each channel\n",
    "for title in ch_names:\n",
    "    power_seizure.plot(picks=title, title=title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average of the epochs to get the evoked response. \n",
    "# This collapses the data across epochs to get the mean evoked potential for each channel.\n",
    "\n",
    "evoked = epochs.average() \n",
    "evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the mapping of event IDs used in the epochs object.\n",
    "\n",
    "epochs.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the averaged evoked data for each condition.\n",
    "my_evokeds = {}\n",
    "\n",
    "# Loop over each condition in the event ID dictionary.\n",
    "for condition in epochs.event_id:\n",
    "    # Loop over each condition in the event ID dictionary.\n",
    "    my_evokeds[condition] = epochs[condition].average()\n",
    "\n",
    "# Print the dictionary of evoked responses.\n",
    "my_evokeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over specified conditions and compute the mean amplitude in a specific time window.\n",
    "\n",
    "for condition in ['Seizure', 'LPD', 'LRDA', 'GRDA', 'Other']:\n",
    "    # Copy the evoked data for the condition, pick the 'Cz' channel, and find the peak in the specified time range.\n",
    "    chan, lat, amp = my_evokeds[condition].copy().pick_channels(['Cz']).get_peak(tmin = -2, tmax = 0, mode = 'neg', return_amplitude = True)\n",
    "    print(condition)\n",
    "    # Print the latency and amplitude (converted to microvolts) of the peak.\n",
    "    print(lat, amp * 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in ['Seizure', 'LPD', 'LRDA', 'GRDA', 'Other']:\n",
    "    # Copy the evoked data for the condition, pick the 'Cz' channel, crop the data to the time window, and calculate the mean.\n",
    "    amp = my_evokeds[condition].copy().pick_channels(['Cz']).crop(tmin = -2, tmax = 0).data.squeeze().mean()\n",
    "   # print(vector.shape)\n",
    "    print(condition)\n",
    "    # Print the mean amplitude (converted to microvolts).\n",
    "    print(amp * 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evoked responses for all conditions on the same plot for comparison.\n",
    "# The plot is inverted in the y-axis to match the EEG/MEG convention in some publications.\n",
    "\n",
    "mne.viz.plot_compare_evokeds(my_evokeds, picks = ['Cz'], invert_y = True) # как то грязно "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the evoked responses to only include the 'Cz' channel.\n",
    "my_evokeds = {condition: evoked.copy().pick_channels(['Cz']) for condition, evoked in my_evokeds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the channel names for the 'Seizure' condition to verify the channel picking.\n",
    "my_evokeds['Seizure'].ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evoked response for the 'Seizure' condition.\n",
    "mne.viz.plot_compare_evokeds(my_evokeds['Seizure'], picks = ['Cz'], invert_y = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evoked response for the 'LPD' condition with a specific color.\n",
    "mne.viz.plot_compare_evokeds(my_evokeds['LPD'], picks = ['Cz'], invert_y = True, colors = ['orange']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evoked response for the 'LRDA' condition with a specific color.\n",
    "mne.viz.plot_compare_evokeds(my_evokeds['LRDA'], picks = ['Cz'], invert_y = True, colors = ['green']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evoked response for the 'GRDA' condition with a specific color.\n",
    "mne.viz.plot_compare_evokeds(my_evokeds['GRDA'], picks = ['Cz'], invert_y = True, colors = ['red']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evoked response for the 'Other' condition with a specific color.\n",
    "mne.viz.plot_compare_evokeds(my_evokeds['Other'], picks = ['Cz'], invert_y = True,  colors = ['purple']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
